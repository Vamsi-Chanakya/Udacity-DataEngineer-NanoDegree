#Project Name
Data Modeling with Postgres

##Project Description & Purpose
This project is created for a startup called sparkify to analyze the Songs and Log Datasets and summarize the details inform of dimensions and fact tables inform of Star Schema.  

##Source(s)
In this project, the data is extracted from 2 set of files which are of JSON file format.

songs data
log data

###Song Dataset
Song dataset contains the metadata about a song, i.e details like artist_id, artist_latitude, artist_location, artist_longitude, artist_name, duration, num_songs, song_id, title, year. Song Dataset is partitioned by first 3 letters of each song's track id.

###Log Dataset
Log Dataset is generated by event simulator based on songs in song dataset. The data is similar to music streaming app activity log and it contains the below mentioned details. Log dataset contains data like artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId

###Target(s)
The data extracted from Source JSON files are loaded into a new Postgres database, named as sparkify. Using the song and log datasets, a star schema is created which is optimized for queries on song play analysis. This includes the following tables.

##Star Schema Details : 

###Dimension Tables:

users - users in the app contains user details like user_id, first_name, last_name, gender, level.

songs - songs in music database contains user details like song_id, title, artist_id, year, duration

artists - artists in music database contains user details like artist_id, name, location, lattitude, longitude

time - timestamps of records in songplays broken down into specific units, contains user details like start_time, hour, day, week, month, year, weekday

###Schema for Song Play Analysis
Fact Table
songplays - records in log data associated with song plays i.e. records with page NextSong,  contains user details like songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent

##ETL process :

###Extraction Process:
Step 1: ETL process is comprised of creating 2 dimension tables which are songs table and artists table from song data (metadat) json file. 
Step 2: In second step we process the log data and create 2 more dimension tables which are time table and users table.

###Transformation process:
In this stage we transform the information from the songs table, artists table, and original log file are all needed for the songplays table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.

###Load process:
In this stage we load the Fact Table SongPlays table by consolidating data from dimension tables. 


##Execution Order:
create_tables.py : This step drops if the dimesion and fact tables already exists and creates them.
etl.py : This step inserts the data into dimension and fact tables. 

##Constraints:
Since multiple connections to the same database (in this case, sparkifydb) is not possible, please make sure to restart the kernel (or kill the exising active connection) before every new run.

References:
1. https://www.python.org/dev/peps/pep-0008/#introduction
2. https://www.w3schools.com/ 
3. https://stackoverflow.com/
